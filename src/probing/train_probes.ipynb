{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed11ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74dfa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/content/drive/MyDrive/probing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2616b739",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefde418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ActivationsDataset(Dataset):\n",
    "    def __init__(self, data_path, layer: int, batches_to_load: int):\n",
    "        self.data_path = data_path\n",
    "        self.layer = layer\n",
    "        self.batches_to_load = batches_to_load\n",
    "\n",
    "        self.activations = activations\n",
    "        self.labels = labels\n",
    "\n",
    "    def _load_activations(self):\n",
    "        activations = torch.load(\n",
    "            f\"{self.data_path}/layer_activations_batch_{i}.pt\" \n",
    "            for i in range(self.batches_to_load)\n",
    "        )\n",
    "        activations = torch.cat(\n",
    "            [torch.load(f\"{self.data_path}/layer_{self.layer}_activations_batch_{i}.pt\") \n",
    "             for i in range(self.batches_to_load)], dim=0\n",
    "        )\n",
    "        return activations\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.activations[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f3947",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    activations_path = f\"/content/drive/MyDrive/probing/activations-0/layers_activations_batch_{i}.pt\"\n",
    "\n",
    "    batch = torch.load(activations_path)\n",
    "    examples = []\n",
    "    for activations in batch:\n",
    "        for layer in range(len(activations)):\n",
    "            dataset_example = {\n",
    "                \"activations\": activations[layer]\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed8af1a",
   "metadata": {},
   "source": [
    "### Probe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c14719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Probe(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbbe53f",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b3568e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.9886660575866699\n",
      "Epoch 2/100, Loss: 0.9498652815818787\n",
      "Epoch 3/100, Loss: 0.9104343056678772\n",
      "Epoch 4/100, Loss: 0.8715340495109558\n",
      "Epoch 5/100, Loss: 0.8335779905319214\n",
      "Epoch 6/100, Loss: 0.7967727184295654\n",
      "Epoch 7/100, Loss: 0.7612372636795044\n",
      "Epoch 8/100, Loss: 0.727043867111206\n",
      "Epoch 9/100, Loss: 0.6942340731620789\n",
      "Epoch 10/100, Loss: 0.6628273725509644\n",
      "Epoch 11/100, Loss: 0.6328264474868774\n",
      "Epoch 12/100, Loss: 0.604220449924469\n",
      "Epoch 13/100, Loss: 0.5769875645637512\n",
      "Epoch 14/100, Loss: 0.5510972142219543\n",
      "Epoch 15/100, Loss: 0.5265117287635803\n",
      "Epoch 16/100, Loss: 0.50318843126297\n",
      "Epoch 17/100, Loss: 0.48108041286468506\n",
      "Epoch 18/100, Loss: 0.4601382613182068\n",
      "Epoch 19/100, Loss: 0.44031065702438354\n",
      "Epoch 20/100, Loss: 0.4215453565120697\n",
      "Epoch 21/100, Loss: 0.40379029512405396\n",
      "Epoch 22/100, Loss: 0.38699349761009216\n",
      "Epoch 23/100, Loss: 0.37110430002212524\n",
      "Epoch 24/100, Loss: 0.3560730218887329\n",
      "Epoch 25/100, Loss: 0.34185168147087097\n",
      "Epoch 26/100, Loss: 0.32839420437812805\n",
      "Epoch 27/100, Loss: 0.31565621495246887\n",
      "Epoch 28/100, Loss: 0.3035956025123596\n",
      "Epoch 29/100, Loss: 0.29217231273651123\n",
      "Epoch 30/100, Loss: 0.28134822845458984\n",
      "Epoch 31/100, Loss: 0.2710874378681183\n",
      "Epoch 32/100, Loss: 0.26135602593421936\n",
      "Epoch 33/100, Loss: 0.25212210416793823\n",
      "Epoch 34/100, Loss: 0.2433556169271469\n",
      "Epoch 35/100, Loss: 0.2350284308195114\n",
      "Epoch 36/100, Loss: 0.22711412608623505\n",
      "Epoch 37/100, Loss: 0.21958792209625244\n",
      "Epoch 38/100, Loss: 0.21242663264274597\n",
      "Epoch 39/100, Loss: 0.20560862123966217\n",
      "Epoch 40/100, Loss: 0.19911356270313263\n",
      "Epoch 41/100, Loss: 0.1929224282503128\n",
      "Epoch 42/100, Loss: 0.18701760470867157\n",
      "Epoch 43/100, Loss: 0.18138247728347778\n",
      "Epoch 44/100, Loss: 0.17600150406360626\n",
      "Epoch 45/100, Loss: 0.17086024582386017\n",
      "Epoch 46/100, Loss: 0.1659451425075531\n",
      "Epoch 47/100, Loss: 0.1612435281276703\n",
      "Epoch 48/100, Loss: 0.15674357116222382\n",
      "Epoch 49/100, Loss: 0.15243412554264069\n",
      "Epoch 50/100, Loss: 0.14830495417118073\n",
      "Epoch 51/100, Loss: 0.1443462073802948\n",
      "Epoch 52/100, Loss: 0.14054884016513824\n",
      "Epoch 53/100, Loss: 0.13690432906150818\n",
      "Epoch 54/100, Loss: 0.1334047019481659\n",
      "Epoch 55/100, Loss: 0.1300424188375473\n",
      "Epoch 56/100, Loss: 0.1268104612827301\n",
      "Epoch 57/100, Loss: 0.12370223551988602\n",
      "Epoch 58/100, Loss: 0.12071152776479721\n",
      "Epoch 59/100, Loss: 0.11783253401517868\n",
      "Epoch 60/100, Loss: 0.11505972594022751\n",
      "Epoch 61/100, Loss: 0.11238797008991241\n",
      "Epoch 62/100, Loss: 0.1098124235868454\n",
      "Epoch 63/100, Loss: 0.10732846707105637\n",
      "Epoch 64/100, Loss: 0.10493180900812149\n",
      "Epoch 65/100, Loss: 0.10261839628219604\n",
      "Epoch 66/100, Loss: 0.1003844141960144\n",
      "Epoch 67/100, Loss: 0.09822619706392288\n",
      "Epoch 68/100, Loss: 0.09614036977291107\n",
      "Epoch 69/100, Loss: 0.09412369132041931\n",
      "Epoch 70/100, Loss: 0.09217309951782227\n",
      "Epoch 71/100, Loss: 0.09028570353984833\n",
      "Epoch 72/100, Loss: 0.08845876157283783\n",
      "Epoch 73/100, Loss: 0.08668971806764603\n",
      "Epoch 74/100, Loss: 0.08497609198093414\n",
      "Epoch 75/100, Loss: 0.08331558108329773\n",
      "Epoch 76/100, Loss: 0.0817059651017189\n",
      "Epoch 77/100, Loss: 0.08014514297246933\n",
      "Epoch 78/100, Loss: 0.07863115519285202\n",
      "Epoch 79/100, Loss: 0.07716207206249237\n",
      "Epoch 80/100, Loss: 0.0757361575961113\n",
      "Epoch 81/100, Loss: 0.07435166835784912\n",
      "Epoch 82/100, Loss: 0.0730070173740387\n",
      "Epoch 83/100, Loss: 0.07170063257217407\n",
      "Epoch 84/100, Loss: 0.07043104618787766\n",
      "Epoch 85/100, Loss: 0.06919685751199722\n",
      "Epoch 86/100, Loss: 0.0679967924952507\n",
      "Epoch 87/100, Loss: 0.06682952493429184\n",
      "Epoch 88/100, Loss: 0.06569383293390274\n",
      "Epoch 89/100, Loss: 0.06458859145641327\n",
      "Epoch 90/100, Loss: 0.06351269781589508\n",
      "Epoch 91/100, Loss: 0.06246509030461311\n",
      "Epoch 92/100, Loss: 0.06144474074244499\n",
      "Epoch 93/100, Loss: 0.0604507178068161\n",
      "Epoch 94/100, Loss: 0.05948210507631302\n",
      "Epoch 95/100, Loss: 0.05853799730539322\n",
      "Epoch 96/100, Loss: 0.057617589831352234\n",
      "Epoch 97/100, Loss: 0.056720029562711716\n",
      "Epoch 98/100, Loss: 0.05584457144141197\n",
      "Epoch 99/100, Loss: 0.0549904964864254\n",
      "Epoch 100/100, Loss: 0.054157059639692307\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 50)\n",
    "y = torch.tensor([[1.0], [0.0], [1.0]])\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 1\n",
    "epochs = 100\n",
    "\n",
    "model = Probe(input_dim=50)\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(x), batch_size):\n",
    "        batch = x[i:i+batch_size]\n",
    "        # inputs = batch[:, :-1]\n",
    "        targets = y[i:i+batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        l = loss(outputs, targets)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {l.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6982cd73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
